# Վեբ-թրաֆիկում Բոտերի Հայտնաբերում Մեքենայական Ուսուցման Միջոցով

**Հեղինակ:** Կարեն Պողոսյան  
**Ամսաթիվ:** 10.11.2025

---

## Ամփոփագիր

Սույն նախագիծը լուծում է վեբ-թրաֆիկում ավտոմատացված բոտերի հայտնաբերման խնդիրը՝ մեքենայական ուսուցման մեթոդների կիրառմամբ։ Իրականացվել է տվյալների խորքային հետազոտական վերլուծություն (EDA), մշակվել են վարքագծային նոր հատկանիշներ և համեմատվել են հինգ դասակարգման ալգորիթմներ։ **Random Forest** մոդելը ցուցաբերել է գերազանց արդյունավետություն՝ հասնելով **F2-Score ~0.995**, ինչը վկայում է բոտերի գրեթե անթերի հայտնաբերման մասին։ Աշխատանքը հիմնավորում է վարքագծային վերլուծության վրա հիմնված մոտեցումների գերազանցությունը և առաջարկում է գործնական լուծում վերլուծական տվյալների որակի բարձրացման և կայքի անվտանգության բարելավման համար։

---

## 1. Նախապատրաստական Փուլ

### 1.1 Խնդրի Նույնականացում
Վեբ-թրաֆիկի տվյալների մեջ թաքնված է անտեսանելի խնդիր՝ ավտոմատացված բոտերի զգալի քանակ, որը խեղաթյուրում է վերլուծական տվյալները, արհեստականորեն ծանրաբեռնում է սերվերները և ստեղծում անվտանգության ռիսկեր։ Այս «աղմկոտ» տվյալների հիման վրա բիզնես որոշումներ կայացնելը հանգեցնում է ռեսուրսների անարդյունավետ օգտագործման։

Դիտարկվեցին երեք ուղղություններ՝ օգտատերերի սեգմենտավորում, թրաֆիկի կանխատեսում և բոտերի հայտնաբերում։ Ընտրվեց վերջինը՝ որպես ամենահրատապ և կիրառական խնդիր։ **visits.csv** տվյալների բազան ընտրվեց որպես հետազոտության հիմնական օբյեկտ։

### 1.2 Նպատակների Սահմանում (SMART)
**Գլխավոր նպատակ:** Ստեղծել ML դասակարգիչ՝ ≥95% F2-Score ցուցանիշով, առաջնահերթություն տալով բոտերի լիարժեք հայտնաբերմանը (Recall)։

**Կոնկրետ խնդիրներ:**
1. Տվյալների խորքային մաքրում և հետազոտական վերլուծություն (EDA)
2. Վարքագծային հատկանիշների ինժեներինգ (Feature Engineering)
3. Առնվազն 4 ալգորիթմի համեմատական վերլուծություն
4. Լավագույն մոդելի ընտրություն՝ Precision, Recall և F2-Score չափանիշներով

### 1.3 Պատճառահետևանքային Վերլուծություն («5 Ինչու»)
1. **Ինչու՞ են որոշ այցելություններ կասկածելի:** Վարքագիծը տարբերվում է մարդկայինից
2. **Ինչո՞վ է տարբերվում:** Չափազանց արագ, մեծ քանակությամբ, ոչ ստանդարտ ժամերի
3. **Ինչու՞ են այդպիսին:** Ավտոմատացված սկրիպտներ են, ոչ թե իրական մարդիկ
4. **Ինչու՞ են սկրիպտներն այդպես աշխատում:** Ծրագրավորված են կրկնվող գործողությունների՝ առանց մարդկային դադարների
5. **Ինչպե՞ս է արտահայտվում տվյալներում:** Մեկ IP-ից բազմաթիվ հարցումներ, ոչ ստանդարտ User-Agent-ներ, փոքր ժամանակային տարբերություններ

Այս վերլուծությունը հիմնավորեց `visits_per_ip`, `time_since_last_visit_ip` և `is_user_agent_bot` հատկանիշների ստեղծումը։

---

## 2. Պլանավորման և Հետազոտության Փուլ

### 2.1 Գրականության Ուսումնասիրություն
Իրականացվեց գիտական գրականության խորքային ուսումնասիրություն (Google Scholar, arXiv.org)՝ ժամանակակից Bot Detection մեթոդների վերաբերյալ։ Վերլուծությունը հաստատեց, որ պարզ կանոնները անարդյունավետ են, և ժամանակակից լուծումները կենտրոնանում են վարքագծային վերլուծության վրա։

### 2.2 Տեխնոլոգիական Գործիքակազմ
- **Pandas:** Տվյալների մշակում և վերլուծություն
- **Matplotlib & Seaborn:** Տեսողական հետազոտություն և EDA
- **Scikit-learn:** ML մոդելների կառուցում, ուսուցում և գնահատում

Նախագիծն ամբողջությամբ իրականացվել է բաց կոդով և անվճար գործիքներով՝ զրոյական ֆինանսական ծախսերով։

---

## 3. Իրականացման Փուլ

### 3.1 Տվյալների Մշակման Pipeline
Նախագծվեց մոդուլային տվյալների մշակման հոսքագիծ՝
1. **Տվյալների բեռնում և մաքրում:** Բացակայող արժեքների լրացում, անվավեր տվյալների հեռացում
2. **Feature Engineering:** Վարքագծային հատկանիշների ստեղծում (IP վիճակագրություն, ժամանակային հատկանիշներ, User-Agent վերլուծություն)
3. **Կոդավորում:** Կատեգորիկ փոփոխականների Label Encoding
4. **Ստանդարտացում:** StandardScaler կիրառում թվային հատկանիշների համար
5. **Մոդելավորում:** Դասակարգման ալգորիթմների ուսուցում և գնահատում

### 3.2 Իրականացում
Լուծումն ամբողջությամբ իրականացվեց **Python 3**-ով՝ Visual Studio Code միջավայրում։ Կոդը կառուցվեց մոդուլային սկզբունքով՝ ապահովելով ընթերցանելիություն, թեստավորելիություն և ընդլայնելիություն։ Կիրառվեց `class_weight='balanced'` պարամետրը՝ դասերի անհավասարակշռությունը շտկելու համար։

---

## 4. Փորձարկման և Արդյունքների Փուլ

### 4.1 Մոդելների Համեմատություն
Փորձարկվեցին 5 ալգորիթմներ՝ տվյալների 70/30 train-test բաժանմամբ։ Գնահատումը կատարվեց hold-out test set-ի վրա՝ ապահովելով օբյեկտիվություն։

**Լավագույն արդյունք՝ Random Forest:**
- **F2-Score:** ~0.995
- **Recall (Bot):** ~0.995 (բաց չի թողնում գրեթե ոչ մի բոտ)
- **Precision (Bot):** ~0.997 (չի արգելափակում իրական օգտատերերին)

### 4.2 Արդյունքների Վերլուծություն
Ստացված արդյունքները զգալիորեն գերազանցեցին սահմանված 95% նպատակը։ Համեմատությունը ցույց տվեց, որ ensemble մեթոդները (Random Forest, Gradient Boosting) զգալիորեն ավելի արդյունավետ են պարզ Decision Tree-ից։

### 4.3 Եզրակացություններ
1. **Վարքագծային հատկանիշները** (visits_per_ip, time_since_last_visit_ip) ապացուցեցին իրենց բարձր կանխատեսողական ուժը
2. **Random Forest**-ը ապահովեց լավագույն Precision-Recall հավասարակշռությունը
3. Համակարգը պատրաստ է արտադրական միջավայրում տեղակայման՝ որպես real-time bot detection լուծում

### 4.4 Հետագա Զարգացման Ուղիներ
- Gradient Boosting հիպերպարամետրերի խորը օպտիմիզացում
- Real-time streaming տվյալների մշակման ինտեգրում
- Deep Learning մոդելների փորձարկում ավելի բարդ օրինաչափությունների համար

---

## Հղումներ և Ռեսուրսներ
- Scikit-learn Documentation: https://scikit-learn.org
- Pandas Documentation: https://pandas.pydata.org
- Bot Detection Research Papers: Google Scholar, arXiv.org
